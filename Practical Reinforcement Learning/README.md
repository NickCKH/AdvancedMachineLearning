##Practical Reinforcement Learning

![Python 3.6](https://img.shields.io/badge/python-3.6-brightgreen)

**Course 4** in the Advance Machine Learning Specialization.
This course was especially interesting for me given that I'm an avid gamer, and seeing a team of 5 AI beat the a team of top DotA players secretly brings joy to me. 

Leveraging on prior knowledge of Deep Learning, we learnt to apply a myriad of Reinforcement Learning techniques, in the OpenAI gym simulated environment. 
Some of the algorithms/techniques learnt include: 
- Fully/Partially observable Markov Decision Processes
- Deep Q networks 
- Exploration/Exploitation algorithms (Epsilon Greedy, Boltzman, Thompson Sampling, UCB1, Bayesian UCB)
- Monte Carlo Tree Search
- Value vs Policy based methods (Q-learning, SARSA, value-iteration, REINFORCE, A3C, Crossentropy method)
- Training tricks/techniques (Experienced replay,  Duelling DQNs, Target networks, Reward clipping)

This has encouraged me to launch my own project to get an AI to play a game from my childhood, will be in my Projects page when I've hit a significant milestone.

I've uploaded two notebooks showcasing: 

https://github.com/NickCKH/AdvancedMachineLearningSpecialization/blob/master/Practical%20Reinforcement%20Learning/Asynchronous_Advantage_Actor_Critic_A3C_nc.ipynb

Asynchronous Advantage Actor Critic ("A3C")

https://github.com/NickCKH/AdvancedMachineLearningSpecialization/blob/master/Practical%20Reinforcement%20Learning/Bandits_nc.ipynb
Exploration/Exploitation algorithms
